{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "copyrighted-compensation",
   "metadata": {},
   "source": [
    "## Can we translate any 'Markov-Chain with biases' to a 'Markov-Chain without biases'\n",
    "**Yes.** \n",
    "Idea: biases are just a deterministic distribution of probability mass. A bias of mass $b_{1j} \\in [0,1]$ on neuron j,\n",
    "can be achieved by (1) scaling down the original weight matrix, by the factor $(1- b_{1j)$, \n",
    "and then (2) adding to every weight $w_{ij} = P(j |Â i) += b_{1j)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bright-airport",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from util.util_lrp_transformation_visualization import norm_arr as a, h0_W_h1_R1_C_R0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "unsigned-onion",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = a(1,2)\n",
    "\n",
    "W = np.array([[.2, .8], \n",
    "              [.9, .1]])\n",
    "W /= W.sum(axis=1, keepdims=True) # normalize (if not already)\n",
    "\n",
    "biases_l1 = np.array([.2, .4])\n",
    "biases_mass = biases_l1.sum()       # -> we want 60% for our entire prob mass to come only from biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "statistical-detail",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3999999999999999\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.33333333, 0.66666667]),\n",
       " array([0.13333333, 0.26666667]),\n",
       " array([0.46666667, 0.53333333]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_t0 = inp * (1 - biases_mass) # -> thus, our input can only contribute 40% of the prob mass\n",
    "\n",
    "states_t1 = W.T @ states_t0\n",
    "print(states_t1.sum())\n",
    "\n",
    "states_t1 += biases_l1\n",
    "print(states_t1.sum())\n",
    "\n",
    "inp, states_t0, states_t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "toxic-promise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.33333333, 0.66666667]),\n",
       " array([0.13333333, 0.26666667, 0.2       , 0.4       ]),\n",
       " array([0.46666667, 0.53333333, 0.        , 0.        ]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_explicit_biases = np.zeros((4,4))\n",
    "W_explicit_biases[:2, :2] = W\n",
    "W_explicit_biases[2, 0] = 1\n",
    "W_explicit_biases[3, 1] = 1\n",
    "\n",
    "states_t0 = np.hstack((\n",
    "    inp * (1 - biases_mass),\n",
    "    biases_l1\n",
    "))\n",
    "\n",
    "states_t1 = W_explicit_biases.T @ states_t0\n",
    "print(states_t1.sum())\n",
    "\n",
    "inp, states_t0, states_t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bound-ratio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.33333333, 0.66666667]),\n",
       " array([0.33333333, 0.66666667]),\n",
       " array([0.46666667, 0.53333333]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_to_account_for_biases = biases_l1[None, :] * np.ones(2)\n",
    "\n",
    "# now include the above in our matrix W:\n",
    "W_implicit_biases = W * (1 - biases_mass) + W_to_account_for_biases # -> thus, our input can only contribute 40% of the prob mass\n",
    "\n",
    "states_t0 = inp\n",
    "\n",
    "states_t1 = W_implicit_biases.T @ states_t0\n",
    "print(states_t1.sum())\n",
    "\n",
    "inp, states_t0, states_t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "typical-buyer",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "h0_W_h1_R1_C_R0() missing 3 required positional arguments: 'w11', 'w12', and 'A1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-76e9bb37e1e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## How does this change the relevancy scores?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mh0_W_h1_R1_C_R0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: h0_W_h1_R1_C_R0() missing 3 required positional arguments: 'w11', 'w12', and 'A1'"
     ]
    }
   ],
   "source": [
    "## How does this change the relevancy scores?\n",
    "h0_W_h1_R1_C_R0()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "played-young",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================\n",
      "\n",
      "h0_eb [0.  0.4 0.2 0.4] \n",
      "\n",
      "h1_eb [0.2 0.8 0.  0. ] \n",
      "\n",
      "C_eb.T \n",
      " [[0.  0.  0.  0. ]\n",
      " [0.  0.5 0.  0. ]\n",
      " [1.  0.  0.  0. ]\n",
      " [0.  0.5 0.  0. ]] \n",
      " the distance: 0.49999999999999994 \n",
      "\n",
      "R0_eb [0.  0.4 0.  0.4] \n",
      "\n",
      "\n",
      "====================\n",
      "\n",
      "h0_eb [0.04 0.36 0.2  0.4 ] \n",
      "\n",
      "h1_eb [0.24 0.76 0.   0.  ] \n",
      "\n",
      "C_eb.T \n",
      " [[0.16666667 0.         0.         0.        ]\n",
      " [0.         0.47368421 0.         0.        ]\n",
      " [0.83333333 0.         0.         0.        ]\n",
      " [0.         0.52631579 0.         0.        ]] \n",
      " the distance: 0.5021498870653232 \n",
      "\n",
      "R0_eb [0.   0.36 0.   0.4 ] \n",
      "\n",
      "\n",
      "====================\n",
      "\n",
      "h0_eb [0.08 0.32 0.2  0.4 ] \n",
      "\n",
      "h1_eb [0.28 0.72 0.   0.  ] \n",
      "\n",
      "C_eb.T \n",
      " [[0.28571429 0.         0.         0.        ]\n",
      " [0.         0.44444444 0.         0.        ]\n",
      " [0.71428571 0.         0.         0.        ]\n",
      " [0.         0.55555556 0.         0.        ]] \n",
      " the distance: 0.528359269114071 \n",
      "\n",
      "R0_eb [0.   0.32 0.   0.4 ] \n",
      "\n",
      "\n",
      "====================\n",
      "\n",
      "h0_eb [0.12 0.28 0.2  0.4 ] \n",
      "\n",
      "h1_eb [0.32 0.68 0.   0.  ] \n",
      "\n",
      "C_eb.T \n",
      " [[0.375      0.         0.         0.        ]\n",
      " [0.         0.41176471 0.         0.        ]\n",
      " [0.625      0.         0.         0.        ]\n",
      " [0.         0.58823529 0.         0.        ]] \n",
      " the distance: 0.5569337240735028 \n",
      "\n",
      "R0_eb [0.   0.28 0.   0.4 ] \n",
      "\n",
      "\n",
      "====================\n",
      "\n",
      "h0_eb [0.16 0.24 0.2  0.4 ] \n",
      "\n",
      "h1_eb [0.36 0.64 0.   0.  ] \n",
      "\n",
      "C_eb.T \n",
      " [[0.44444444 0.         0.         0.        ]\n",
      " [0.         0.375      0.         0.        ]\n",
      " [0.55555556 0.         0.         0.        ]\n",
      " [0.         0.625      0.         0.        ]] \n",
      " the distance: 0.5815117059849534 \n",
      "\n",
      "R0_eb [0.   0.24 0.   0.4 ] \n",
      "\n",
      "\n",
      "====================\n",
      "\n",
      "h0_eb [0.2 0.2 0.2 0.4] \n",
      "\n",
      "h1_eb [0.4 0.6 0.  0. ] \n",
      "\n",
      "C_eb.T \n",
      " [[0.5        0.         0.         0.        ]\n",
      " [0.         0.33333333 0.         0.        ]\n",
      " [0.5        0.         0.         0.        ]\n",
      " [0.         0.66666667 0.         0.        ]] \n",
      " the distance: 0.6009252125773314 \n",
      "\n",
      "R0_eb [0.  0.2 0.  0.4] \n",
      "\n",
      "\n",
      "====================\n",
      "\n",
      "h0_eb [0.24 0.16 0.2  0.4 ] \n",
      "\n",
      "h1_eb [0.44 0.56 0.   0.  ] \n",
      "\n",
      "C_eb.T \n",
      " [[0.54545455 0.         0.         0.        ]\n",
      " [0.         0.28571429 0.         0.        ]\n",
      " [0.45454545 0.         0.         0.        ]\n",
      " [0.         0.71428571 0.         0.        ]] \n",
      " the distance: 0.61575426447427 \n",
      "\n",
      "R0_eb [0.   0.16 0.   0.4 ] \n",
      "\n",
      "\n",
      "====================\n",
      "\n",
      "h0_eb [0.28 0.12 0.2  0.4 ] \n",
      "\n",
      "h1_eb [0.48 0.52 0.   0.  ] \n",
      "\n",
      "C_eb.T \n",
      " [[0.58333333 0.         0.         0.        ]\n",
      " [0.         0.23076923 0.         0.        ]\n",
      " [0.41666667 0.         0.         0.        ]\n",
      " [0.         0.76923077 0.         0.        ]] \n",
      " the distance: 0.6273214611724998 \n",
      "\n",
      "R0_eb [0.   0.12 0.   0.4 ] \n",
      "\n",
      "\n",
      "====================\n",
      "\n",
      "h0_eb [0.32 0.08 0.2  0.4 ] \n",
      "\n",
      "h1_eb [0.52 0.48 0.   0.  ] \n",
      "\n",
      "C_eb.T \n",
      " [[0.61538462 0.         0.         0.        ]\n",
      " [0.         0.16666667 0.         0.        ]\n",
      " [0.38461538 0.         0.         0.        ]\n",
      " [0.         0.83333333 0.         0.        ]] \n",
      " the distance: 0.6375547055977617 \n",
      "\n",
      "R0_eb [0.32 0.   0.2  0.  ] \n",
      "\n",
      "\n",
      "====================\n",
      "\n",
      "h0_eb [0.36 0.04 0.2  0.4 ] \n",
      "\n",
      "h1_eb [0.56 0.44 0.   0.  ] \n",
      "\n",
      "C_eb.T \n",
      " [[0.64285714 0.         0.         0.        ]\n",
      " [0.         0.09090909 0.         0.        ]\n",
      " [0.35714286 0.         0.         0.        ]\n",
      " [0.         0.90909091 0.         0.        ]] \n",
      " the distance: 0.6492532394469559 \n",
      "\n",
      "R0_eb [0.36 0.   0.2  0.  ] \n",
      "\n",
      "\n",
      "====================\n",
      "\n",
      "h0_eb [0.4 0.  0.2 0.4] \n",
      "\n",
      "h1_eb [0.6 0.4 0.  0. ] \n",
      "\n",
      "C_eb.T \n",
      " [[0.66666667 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.33333333 0.         0.         0.        ]\n",
      " [0.         1.         0.         0.        ]] \n",
      " the distance: 0.6666666666666666 \n",
      "\n",
      "R0_eb [0.4 0.  0.2 0. ] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-108-b9190294a010>:25: RuntimeWarning: invalid value encountered in true_divide\n",
      "  C_eb /= C_eb.sum(axis=1, keepdims=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "W = np.array([[0.6, 0.2],\n",
    "              [0.4, 0.8]])\n",
    "\n",
    "for p1 in np.linspace(0., 1., 11):\n",
    "    print(\"\\n\"+\"=\"*20+\"\\n\")\n",
    "    h0 = a(p1,1-p1)\n",
    "\n",
    "    # explicit biases\n",
    "    W_eb = np.block([[(W - W.min(axis=1, keepdims=True)), np.eye(2)], \n",
    "                     [np.zeros((2,4))]])\n",
    "    W_eb /= W_eb.sum(axis=0, keepdims=True)\n",
    "    # print(\"W_eb \\n\", W_eb, '\\n')\n",
    "\n",
    "    biases = W.min(axis=1)\n",
    "    biases_mass = biases.sum()\n",
    "    assert(biases_mass <= 1)\n",
    "\n",
    "    h0_eb = np.hstack((h0 * (1 - biases_mass), biases))\n",
    "    print(\"h0_eb\", h0_eb, '\\n')\n",
    "\n",
    "    h1_eb = W_eb @ h0_eb\n",
    "    print(\"h1_eb\", h1_eb, '\\n')\n",
    "\n",
    "    C_eb = W_eb * h0_eb[None, :]\n",
    "    C_eb /= C_eb.sum(axis=1, keepdims=True)\n",
    "    C_eb[np.isnan(C_eb)] = 0\n",
    "    print(\"C_eb.T \\n\", C_eb.T, '\\n the distance:', np.sqrt(np.sum((C_eb.T[:2, 0] - C_eb.T[:2, 1])**2)), '\\n')\n",
    "\n",
    "    R1_eb = h1_eb * (h1_eb == h1_eb.max())\n",
    "    # print(\"R1_eb\", R1_eb, '\\n')\n",
    "\n",
    "    R0_eb = C_eb.T @ R1_eb\n",
    "    print(\"R0_eb\", R0_eb, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-syria",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
